{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import UpSampling2D, Conv2D, Activation, BatchNormalization, Reshape, Dense, Input, LeakyReLU, Dropout, Flatten, ZeroPadding2D\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import glob\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import argparse\n",
    "from ast import literal_eval\n",
    "from imageio import imwrite as imsave\n",
    "#from scipy.misc import imsave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCGAN:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.img_size = (64,64)\n",
    "        self.upsample_layers = 5\n",
    "        self.starting_filters = 64\n",
    "        self.kernel_size = 3\n",
    "        self.channels = 3\n",
    "        self.output_directory = \"\"\n",
    "\n",
    "    def build_generator(self):\n",
    "        noise_shape = (100,)\n",
    "\n",
    "        # This block of code can be a little daunting, but essentially it automatically calculates the required starting\n",
    "        # array size that will be correctly upscaled to our desired image size.\n",
    "        #\n",
    "        # We have 5 Upsample2D layers which each double the images width and height, so we can determine the starting\n",
    "        # x size by taking (x / 2^upsample_count) So for our target image size, 256x192, we do the following:\n",
    "        # x = (192 / 2^5), y = (256 / 2^5) [x and y are reversed within the model]\n",
    "        # We also need a 3rd dimension which is chosen relatively arbitrarily, in this case it's 64.\n",
    "        model = Sequential()\n",
    "        model.add(\n",
    "            Dense(self.starting_filters * (self.img_size[0] // (2 ** self.upsample_layers))  *  (self.img_size[1] // (2 ** self.upsample_layers)),\n",
    "                  activation=\"relu\", input_shape=noise_shape))\n",
    "        model.add(Reshape(((self.img_size[0] // (2 ** self.upsample_layers)),\n",
    "                           (self.img_size[1] // (2 ** self.upsample_layers)),\n",
    "                           self.starting_filters)))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "\n",
    "        model.add(UpSampling2D())  # 6x8 -> 12x16\n",
    "        model.add(Conv2D(1024, kernel_size=self.kernel_size, padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "\n",
    "        model.add(UpSampling2D())  # 12x16 -> 24x32\n",
    "        model.add(Conv2D(512, kernel_size=self.kernel_size, padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "\n",
    "        model.add(UpSampling2D())  # 24x32 -> 48x64\n",
    "        model.add(Conv2D(256, kernel_size=self.kernel_size, padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "\n",
    "        model.add(UpSampling2D())  # 48x64 -> 96x128\n",
    "        model.add(Conv2D(128, kernel_size=self.kernel_size, padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "\n",
    "        model.add(UpSampling2D())  # 96x128 -> 192x256\n",
    "        model.add(Conv2D(64, kernel_size=self.kernel_size, padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "\n",
    "        model.add(Conv2D(32, kernel_size=self.kernel_size, padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "\n",
    "        model.add(Conv2D(self.channels, kernel_size=self.kernel_size, padding=\"same\"))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        noise = Input(shape=noise_shape)\n",
    "        img = model(noise)\n",
    "\n",
    "        return Model(noise, img)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        img_shape = (self.img_size[0], self.img_size[1], self.channels)\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Conv2D(32, kernel_size=self.kernel_size, strides=2, input_shape=img_shape, padding=\"same\"))  # 192x256 -> 96x128\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "        model.add(Conv2D(64, kernel_size=self.kernel_size, strides=2, padding=\"same\"))  # 96x128 -> 48x64\n",
    "        model.add(ZeroPadding2D(padding=((0, 1), (0, 1))))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "\n",
    "        model.add(Conv2D(128, kernel_size=self.kernel_size, strides=2, padding=\"same\"))  # 48x64 -> 24x32\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "\n",
    "        model.add(Conv2D(256, kernel_size=self.kernel_size, strides=1, padding=\"same\"))  # 24x32 -> 12x16\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "        model.add(Conv2D(512, kernel_size=self.kernel_size, strides=1, padding=\"same\"))  # 12x16 -> 6x8\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        img = Input(shape=img_shape)\n",
    "        validity = model(img)\n",
    "\n",
    "        return Model(img, validity)\n",
    "\n",
    "    def build_gan(self):\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy',\n",
    "                                   optimizer=optimizer,\n",
    "                                   metrics=['accuracy'])\n",
    "\n",
    "        self.generator = self.build_generator()\n",
    "        self.generator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "        # These next few lines setup the training for the GAN model\n",
    "        z = Input(shape=(100,))\n",
    "        img = self.generator(z)\n",
    "\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        valid = self.discriminator(img)\n",
    "\n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "    def load_imgs(self, image_path):\n",
    "        X_train = []\n",
    "        for i in glob.glob(image_path):\n",
    "            img = Image.open(i)\n",
    "            img = np.asarray(img)\n",
    "            X_train.append(img)\n",
    "        return np.asarray(X_train)\n",
    "\n",
    "    def train(self, epochs, image_path, batch_size=32, save_interval=50):\n",
    "        self.build_gan()\n",
    "        X_train = self.load_imgs(image_path)\n",
    "        print(\"Training Data Shape: \", X_train.shape)\n",
    "\n",
    "        # Rescale images from -1 to 1\n",
    "        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "\n",
    "        half_batch = batch_size // 2\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "\n",
    "            # Train Generator\n",
    "            noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "            g_loss = self.combined.train_on_batch(noise, np.ones((batch_size, 1)))\n",
    "\n",
    "\n",
    "\n",
    "            # Train Discriminator\n",
    "            idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
    "            imgs = X_train[idx]\n",
    "\n",
    "            # Sample noise and generate a half batch of new images\n",
    "            noise = np.random.normal(0, 1, (half_batch, 100))\n",
    "            gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "            # Train the discriminator (real classified as ones and generated as zeros)\n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs, np.ones((half_batch, 1)))\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "            # Print progress\n",
    "            print(f\"{epoch} [D loss: {d_loss[0]} | D Accuracy: {100 * d_loss[1]}] [G loss: {g_loss}]\")\n",
    "\n",
    "            # If at save interval => save generated image samples, save model files\n",
    "            if epoch % (save_interval) == 0:\n",
    "\n",
    "                self.save_imgs(epoch)\n",
    "\n",
    "                save_path = self.output_directory + \"/models\"\n",
    "                if not os.path.exists(save_path):\n",
    "                    os.makedirs(save_path)\n",
    "                self.discriminator.save(save_path + \"/discrim.h5\")\n",
    "                self.generator.save(save_path + \"/generat.h5\")\n",
    "\n",
    "    def gene_imgs(self, count):\n",
    "        # Generate images from the currently loaded model\n",
    "        noise = np.random.normal(0, 1, (count, 100))\n",
    "        return self.generator.predict(noise)\n",
    "\n",
    "    def save_imgs(self, epoch):\n",
    "        r, c = 5, 5\n",
    "\n",
    "        # Generates r*c images from the model, saves them individually and as a gallery\n",
    "\n",
    "        imgs = self.gene_imgs(r*c)\n",
    "        imgs = 0.5 * imgs + 0.5\n",
    "\n",
    "        for i, img_array in enumerate(imgs):\n",
    "            path = f\"{self.output_directory}/generated_{self.img_size[0]}x{self.img_size[1]}\"\n",
    "            if not os.path.exists(path):\n",
    "                os.makedirs(path)\n",
    "            imsave(path + f\"/{epoch}_{i}.png\", img_array)\n",
    "\n",
    "        nindex, height, width, intensity = imgs.shape\n",
    "        nrows = nindex // c\n",
    "        assert nindex == nrows * c\n",
    "        # want result.shape = (height*nrows, width*ncols, intensity)\n",
    "        gallery = (imgs.reshape(nrows, c, height, width, intensity)\n",
    "                  .swapaxes(1, 2)\n",
    "                  .reshape(height * nrows, width * c, intensity))\n",
    "\n",
    "        path = f\"{self.output_directory}/gallery_generated_{self.img_size[0]}x{self.img_size[1]}\"\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "        imsave(path + f\"/{epoch}.png\", gallery)\n",
    "\n",
    "    def generate_imgs(self, count, threshold, modifier):\n",
    "        self.build_gan()\n",
    "\n",
    "        # Generates (count) images from the model ensuring the discriminator scores them between the threshold values\n",
    "        # and saves them\n",
    "\n",
    "        imgs = []\n",
    "        for i in range(count):\n",
    "            score = [0]\n",
    "            while not(threshold[0] < score[0] < threshold[1]):\n",
    "                img = self.gene_imgs(1)\n",
    "                score = self.discriminator.predict(img)\n",
    "            print(\"Image found: \", score[0])\n",
    "            imgs.append(img)\n",
    "\n",
    "        imgs = np.asarray(imgs).squeeze()\n",
    "        imgs = 0.5 * imgs + 0.5\n",
    "\n",
    "        print(imgs.shape)\n",
    "        for i, img_array in enumerate(imgs):\n",
    "            path = f\"{self.output_directory}/generated_{threshold[0]}_{threshold[1]}\"\n",
    "            if not os.path.exists(path):\n",
    "                os.makedirs(path)\n",
    "            imsave(path + f\"/{modifier}_{i}.png\", img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--load_generator', help='Path to existing generator weights file', default=\"../data/models/generat.h5\")\n",
    "    parser.add_argument('--load_discriminator', help='Path to existing discriminator weights file', default=\"../data/models/discrim.h5\")\n",
    "    parser.add_argument('--data', help='Path to directory of images of correct dimensions, using *.[filetype] (e.g. *.png) to reference images', default=\"../data/resized/paintings_256x/*.png\")\n",
    "    parser.add_argument('--sample', help='If given, will generate that many samples from existing model instead of training', default=-1)\n",
    "    parser.add_argument('--sample_thresholds', help='The values between which a generated image must score from the discriminator', default=\"(0.0, 0.1)\")\n",
    "    parser.add_argument('--batch_size', help='Number of images to train on at once', default=24)\n",
    "    parser.add_argument('--image_size', help='Size of images as tuple (height,width). Height and width must both be divisible by (2^5)', default=\"(192, 256)\")\n",
    "    parser.add_argument('--epochs', help='Number of epochs to train for', default=500000)\n",
    "    parser.add_argument('--save_interval', help='How many epochs to go between saves/outputs', default=100)\n",
    "    parser.add_argument('--output_directory', help=\"Directoy to save weights and images to.\", default=\"../data/output/test\")\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    dcgan = DCGAN(args.load_discriminator, args.load_generator, args.output_directory, literal_eval(args.image_size))\n",
    "    if args.sample == -1:\n",
    "        dcgan.train(epochs=int(args.epochs), image_path=args.data, batch_size=int(args.batch_size), save_interval=int(args.save_interval))\n",
    "    else:\n",
    "        dcgan.generate_imgs(int(args.sample), literal_eval(args.sample_thresholds), \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_73 (Conv2D)           (None, 14, 14, 32)        896       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_31 (LeakyReLU)   (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_74 (Conv2D)           (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_7 (ZeroPaddin (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_32 (LeakyReLU)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_55 (Batc (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv2d_75 (Conv2D)           (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_33 (LeakyReLU)   (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_56 (Batc (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_76 (Conv2D)           (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_34 (LeakyReLU)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_77 (Conv2D)           (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_35 (LeakyReLU)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 8193      \n",
      "=================================================================\n",
      "Total params: 1,577,537\n",
      "Trainable params: 1,577,153\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_14 (Dense)             (None, 0)                 0         \n",
      "_________________________________________________________________\n",
      "reshape_7 (Reshape)          (None, 0, 0, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_57 (Batc (None, 0, 0, 64)          256       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_31 (UpSampling (None, 0, 0, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_78 (Conv2D)           (None, 0, 0, 1024)        590848    \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 0, 0, 1024)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_58 (Batc (None, 0, 0, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_32 (UpSampling (None, 0, 0, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_79 (Conv2D)           (None, 0, 0, 512)         4719104   \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 0, 0, 512)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_59 (Batc (None, 0, 0, 512)         2048      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_33 (UpSampling (None, 0, 0, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_80 (Conv2D)           (None, 0, 0, 256)         1179904   \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 0, 0, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_60 (Batc (None, 0, 0, 256)         1024      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_34 (UpSampling (None, 0, 0, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_81 (Conv2D)           (None, 0, 0, 128)         295040    \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 0, 0, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_61 (Batc (None, 0, 0, 128)         512       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_35 (UpSampling (None, 0, 0, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_82 (Conv2D)           (None, 0, 0, 64)          73792     \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 0, 0, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_62 (Batc (None, 0, 0, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv2d_83 (Conv2D)           (None, 0, 0, 32)          18464     \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 0, 0, 32)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_63 (Batc (None, 0, 0, 32)          128       \n",
      "_________________________________________________________________\n",
      "conv2d_84 (Conv2D)           (None, 0, 0, 3)           867       \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 0, 0, 3)           0         \n",
      "=================================================================\n",
      "Total params: 6,886,339\n",
      "Trainable params: 6,882,179\n",
      "Non-trainable params: 4,160\n",
      "_________________________________________________________________\n",
      "Training Data Shape:  (0,)\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " output dimensions must be positive\n\t [[node model_20/sequential_14/up_sampling2d_31/ResizeNearestNeighbor (defined at C:\\Users\\santi\\anaconda3\\envs\\gpu2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3009) ]] [Op:__inference_keras_scratch_graph_39395]\n\nFunction call stack:\nkeras_scratch_graph\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-886f9520ea82>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdcgan\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDCGAN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdcgan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'/source/trainingSet/trainingSet/9/*.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-13-cb4af01ee1b2>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, epochs, image_path, batch_size, save_interval)\u001b[0m\n\u001b[0;32m    151\u001b[0m             \u001b[1;31m# Train Generator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m             \u001b[0mnoise\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m             \u001b[0mg_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcombined\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\gpu2\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1514\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1516\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\gpu2\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3727\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3729\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\gpu2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1550\u001b[0m     \"\"\"\n\u001b[1;32m-> 1551\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1552\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1553\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\gpu2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1591\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1593\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\gpu2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\gpu2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\gpu2\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m:  output dimensions must be positive\n\t [[node model_20/sequential_14/up_sampling2d_31/ResizeNearestNeighbor (defined at C:\\Users\\santi\\anaconda3\\envs\\gpu2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3009) ]] [Op:__inference_keras_scratch_graph_39395]\n\nFunction call stack:\nkeras_scratch_graph\n"
     ]
    }
   ],
   "source": [
    "dcgan = DCGAN()\n",
    "dcgan.train(epochs=10, image_path='/source/trainingSet/trainingSet/9/*.png')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu2",
   "language": "python",
   "name": "gpu2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
